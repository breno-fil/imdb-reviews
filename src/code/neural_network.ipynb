{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementação CNN para Reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Configuração de Ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.1 Importação de bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r neural_network_req.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZIEF0jFhhB3"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.layers import TextVectorization\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist, RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "from keras.utils import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2. Variáveis de Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sEPmPuFh4Qx",
        "outputId": "3a8f297a-00d0-4529-82b4-8493ebca040f"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "dir_paths = [\n",
        "    '../dist/reviews/negativos',\n",
        "    '../dist/reviews/positivos'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BNBgtJ8iML1",
        "outputId": "8a909411-225c-4104-f644-6b9129401dff"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv('/content/reviews.csv')\n",
        "# df.shape\n",
        "\n",
        "total_files = 0\n",
        "\n",
        "for path in dir_paths: total_files += len(os.listdir(path))\n",
        "\n",
        "df = pd.DataFrame(data=[],columns=['review', 'sentiment'], index=list(range(0, total_files)))\n",
        "\n",
        "for path in dir_paths:\n",
        "\n",
        "    for filepath in os.listdir(path):\n",
        "        index = int(filepath.split('-')[0])\n",
        "\n",
        "        if ('negative' in filepath): sentiment = 'negative'\n",
        "        else: sentiment = 'positive'\n",
        "\n",
        "        with open(os.path.join(path, filepath), 'r', encoding='utf-8') as file:\n",
        "            content = file.read().rstrip('\\n')\n",
        "            df.iloc[index] = [content, sentiment]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hHraJTNZi3Hu",
        "outputId": "4f698ace-cf43-4285-8683-4cb4cdac6b0e"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k931SvHhCPwM"
      },
      "outputs": [],
      "source": [
        "emoji_clean= re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "\n",
        "def remove_emoji(text):\n",
        "  return emoji_clean.sub(r'',text)\n",
        "\n",
        "df['review'] = df['review'].apply(remove_emoji)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UCWejI7mfXP"
      },
      "outputs": [],
      "source": [
        "pattern = r'(<br>|<br />|http)'\n",
        "df['review'] = df['review'].str.replace(pattern, \"\", regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-qAK1tpmmd-"
      },
      "outputs": [],
      "source": [
        "def remove_symbols_and_numbers(text):\n",
        "    cleaned_text = re.sub(r'[^\\w\\s]|[\\d]', '', text)\n",
        "    return cleaned_text.lower()\n",
        "\n",
        "df['review'] = df['review'].apply(remove_symbols_and_numbers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pc6tnAwEmueB"
      },
      "outputs": [],
      "source": [
        "df['review'] = df['review'].apply(word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrD7pnP6m8UY"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return [token for token in tokens if token.lower() not in stop_words]\n",
        "\n",
        "df['review'] = df['review'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4t0YBsTnZJG"
      },
      "outputs": [],
      "source": [
        "def lemmatize_text(tokens):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "df['review'] = df['review'].apply(lemmatize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G2T7bCEnGcz"
      },
      "outputs": [],
      "source": [
        "def join_tokens(tokens):\n",
        "  return ' '.join(tokens);\n",
        "\n",
        "df['review'] = df['review'].apply(join_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-Id8SpInR2f"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "df['sentiment_encoded'] = le.fit_transform(df.sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIKQ0xw4EU7I"
      },
      "outputs": [],
      "source": [
        "vocab_size = 6000\n",
        "sequence_length = 100\n",
        "maxlen = 130\n",
        "\n",
        "x = df['review']\n",
        "y = df['sentiment_encoded']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
        "\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(X_train)\n",
        "\n",
        "train_sequences = token.texts_to_sequences(X_train)\n",
        "valid_sequences = token.texts_to_sequences(X_test)\n",
        "\n",
        "X_train = pad_sequences(train_sequences, maxlen=maxlen, padding = 'post')\n",
        "X_test = pad_sequences(valid_sequences, maxlen=maxlen, padding = 'post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UMKh6ijPPsR",
        "outputId": "fda901f7-9a34-4b0a-aa5a-b8038568f79f"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZBBnN01LWi-",
        "outputId": "c9110539-55c5-42a0-a5a4-7852613cf277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_31 (Embedding)    (None, None, 128)         768000    \n",
            "                                                                 \n",
            " bidirectional_31 (Bidirect  (None, None, 64)          41216     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_max_pooling1d_19 (G  (None, 64)                0         \n",
            " lobalMaxPooling1D)                                              \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 20)                1300      \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 20)                0         \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 810537 (3.09 MB)\n",
            "Trainable params: 810537 (3.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, AveragePooling1D, Dense, LSTM, Embedding, Dropout\n",
        "from keras.losses import BinaryCrossentropy\n",
        "\n",
        "base_model = Sequential()\n",
        "base_model.add(Embedding(vocab_size, 128))\n",
        "base_model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
        "base_model.add(GlobalMaxPool1D())\n",
        "base_model.add(Dense(20, activation=\"relu\"))\n",
        "base_model.add(Dropout(0.05))\n",
        "base_model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "base_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "base_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIoF1gudMMPg",
        "outputId": "8d24278f-0d08-401d-f4a7-8e7bc6f3258f"
      },
      "outputs": [],
      "source": [
        "history = base_model.fit(\n",
        "    X_train, \n",
        "    y_train,\n",
        "    epochs=3,\n",
        "    validation_data=(X_test, y_test)\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_34 (Embedding)    (None, None, 128)         768000    \n",
            "                                                                 \n",
            " bidirectional_34 (Bidirect  (None, None, 64)          41216     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_max_pooling1d_20 (G  (None, 64)                0         \n",
            " lobalMaxPooling1D)                                              \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 809541 (3.09 MB)\n",
            "Trainable params: 809541 (3.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "relu_model = Sequential()\n",
        "relu_model.add(Embedding(vocab_size, 128))\n",
        "relu_model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
        "relu_model.add(GlobalMaxPool1D())\n",
        "relu_model.add(Dense(5, activation='relu'))\n",
        "relu_model.add(Dropout(0.05))\n",
        "\n",
        "relu_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "relu_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = relu_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=3,\n",
        "    validation_data=(X_test, y_test)\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_33 (Embedding)    (None, None, 128)         768000    \n",
            "                                                                 \n",
            " bidirectional_33 (Bidirect  (None, None, 64)          41216     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, None, 5)           325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 809541 (3.09 MB)\n",
            "Trainable params: 809541 (3.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "softmax_model = Sequential()\n",
        "softmax_model.add(Embedding(vocab_size, 128))\n",
        "softmax_model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
        "softmax_model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "softmax_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "softmax_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = softmax_model.fit(\n",
        "    X_train, \n",
        "    y_train,\n",
        "    epochs=3,\n",
        "    validation_data=(X_test, y_test)\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqxccFQQS2rJ"
      },
      "outputs": [],
      "source": [
        "def predict_text(input_text, tokenizer, model, maxlen_seq=128, padding = 'post', truncating = 'post'):\n",
        "    text = str(input_text)\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    sequence = pad_sequences(sequence, maxlen = maxlen_seq,\n",
        "                                                          padding = padding, truncating = truncating)\n",
        "    predict = model.predict(sequence)\n",
        "    return predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCyRa_fNTp9_",
        "outputId": "e5a9400f-255b-40f8-bde3-c86702d9aa18"
      },
      "outputs": [],
      "source": [
        "predict_text('hands down the best movie i ever watched.', token, base_model)\n",
        "predict_text('hands down the best movie i ever watched.', token, relu_model)\n",
        "predict_text('hands down the best movie i ever watched.', token, softmax_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "cell_execution_strategy": "setup",
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
